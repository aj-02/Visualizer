{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShashwatRoutray1/Streamlit__app/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "V-7Oa0BiE-tm"
      },
      "outputs": [],
      "source": [
        "!pip install OpenAI pipenv langchain -q streamlit faker pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-y_DYs2E_cn",
        "outputId": "c765ee54-8212-40ab-dc97-037dd14c904e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## Installing the NodeSource Node.js 18.x repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:3 https://deb.nodesource.com/node_18.x jammy InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 227 kB in 2s (123 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Confirming \"jammy\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_18.x/dists/jammy/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 18.x repo...\n",
            "\n",
            "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_18.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_18.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:7 https://deb.nodesource.com/node_18.x jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 109 kB in 2s (60.4 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 18.x and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
            "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "nodejs is already the newest version (18.17.1-deb-1nodesource1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!curl -sL https://deb.nodesource.com/setup_lts.x | sudo -E bash -\n",
        "!sudo apt-get install -y nodejs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QcSPeUgFGW6",
        "outputId": "2c9db747-f6be-4252-c3d3-1a5dc4bcbe6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "up to date, audited 23 packages in 2s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YXn1lchFHTz",
        "outputId": "f3ee9af5-e771-4bb2-db59-cc330bc01d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created successfully.\n"
          ]
        }
      ],
      "source": [
        "from faker import Faker\n",
        "import csv\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "num_rows = 10\n",
        "filename = 'employee_data.csv'\n",
        "\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "\n",
        "    writer.writerow(['Name', 'Age', 'Income', 'Savings'])\n",
        "\n",
        "\n",
        "    for _ in range(num_rows):\n",
        "        name = fake.name()\n",
        "        age = fake.random_int(min=22, max=65)\n",
        "        income = fake.random_int(min=3000, max=10000)\n",
        "        savings = fake.random_int(min=0, max=income)\n",
        "\n",
        "        writer.writerow([name, age, income, savings])\n",
        "\n",
        "print(\"CSV file created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "gFXn70QaFLJ0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "from langchain import OpenAI\n",
        "from langchain.agents import create_pandas_dataframe_agent\n",
        "import pandas as pd\n",
        "import json\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "def ask_agent(agent, query):\n",
        "    \"\"\"\n",
        "    Query an agent and return the response as a string.\n",
        "\n",
        "    Args:\n",
        "        agent: The agent to query.\n",
        "        query: The query to ask the agent.\n",
        "\n",
        "    Returns:\n",
        "        The response from the agent as a string.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = (\n",
        "        \"\"\"\n",
        "        Let's decode the way to respond to the queries. The responses depend on the type of information requested in the query.\n",
        "\n",
        "        1. If the query requires a table, format your answer like this:\n",
        "           {\"table\": {\"columns\": [\"column1\", \"column2\", ...], \"data\": [[value1, value2, ...], [value1, value2, ...], ...]}}\n",
        "\n",
        "        2. For a bar chart, respond like this:\n",
        "           {\"bar\": {\"columns\": [\"A\", \"B\", \"C\", ...], \"data\": [25, 24, 10, ...]}}\n",
        "\n",
        "        3. If a line chart is more appropriate, your reply should look like this:\n",
        "           {\"line\": {\"columns\": [\"A\", \"B\", \"C\", ...], \"data\": [25, 24, 10, ...]}}\n",
        "\n",
        "        4. For a plain question that doesn't need a chart or table, your response should be:\n",
        "           {\"answer\": \"Your answer goes here\"}\n",
        "\n",
        "        For example:\n",
        "           {\"answer\": \"The Product with the highest Orders is '15143Exfo'\"}\n",
        "\n",
        "        5. If the answer is not known or available, respond with:\n",
        "           {\"answer\": \"I do not know.\"}\n",
        "\n",
        "        Return all output as a string. Remember to encase all strings in the \"columns\" list and data list in double quotes.\n",
        "        For example: {\"columns\": [\"Name\", \"Income\"], \"data\": [[\"51993Masc\", 191], [\"49631Foun\", 152]]}\n",
        "\n",
        "        Now, let's tackle the query step by step. Here's the query for you to work on:\n",
        "        \"\"\"\n",
        "        + query\n",
        "    )\n",
        "\n",
        "    response = agent.run(prompt)\n",
        "\n",
        "    return str(response)\n",
        "\n",
        "\n",
        "def write_answer(response_dict: dict):\n",
        "    \"\"\"\n",
        "    Write a response from an agent to a Streamlit app.\n",
        "\n",
        "    Args:\n",
        "        response_dict: The response from the agent.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if \"bar\" in response_dict:\n",
        "        data = response_dict[\"bar\"]\n",
        "        if isinstance(data, dict):\n",
        "            try:\n",
        "                df_data = {\n",
        "                    col: [x[i] if isinstance(x, list) else x for x in data['data']]\n",
        "                    for i, col in enumerate(data['columns'])\n",
        "                }\n",
        "                df = pd.DataFrame(df_data)\n",
        "                st.bar_chart(df)\n",
        "            except ValueError:\n",
        "                print(f\"Couldn't create chart from data: {data}\")\n",
        "        else:\n",
        "            print(f\"Invalid data format for 'bar' chart: {data}\")\n",
        "\n",
        "\n",
        "    if \"line\" in response_dict:\n",
        "        data = response_dict[\"line\"]\n",
        "        if isinstance(data, dict):\n",
        "            try:\n",
        "                df_data = {\n",
        "                    col: [x[i] for x in data['data']] for i, col in enumerate(data['columns'])\n",
        "                }\n",
        "                df = pd.DataFrame(df_data)\n",
        "                st.line_chart(df)  # Pass the DataFrame to st.line_chart\n",
        "            except ValueError:\n",
        "                print(f\"Couldn't create chart from data: {data}\")\n",
        "        else:\n",
        "            print(f\"Invalid data format for 'line' chart: {data}\")\n",
        "\n",
        "    if \"table\" in response_dict:\n",
        "        data = response_dict[\"table\"]\n",
        "        if isinstance(data, dict):\n",
        "            df = pd.DataFrame(data[\"data\"], columns=data[\"columns\"])\n",
        "            st.table(df)\n",
        "        else:\n",
        "            print(f\"Invalid data format for 'table': {data}\")\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"employee_data.csv\")\n",
        "agent = create_pandas_dataframe_agent(OpenAI(temperature=0), df, verbose=True)\n",
        "agent.run(\"plot a graph of first 5 employees and their savings\")\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"👨‍💻 Talk with your CSV\")\n",
        "st.title(\"👨‍💻 Talk with your CSV\")\n",
        "\n",
        "st.write(\"Write your Query below.\")\n",
        "\n",
        "query = st.text_area(\"Send a Message\")\n",
        "\n",
        "if st.button(\"Submit Query\", type=\"primary\"):\n",
        "\n",
        "    df = pd.read_csv(\"employee_data.csv\")\n",
        "    agent = create_pandas_dataframe_agent(OpenAI(temperature=0), df, verbose=True)\n",
        "    agent.run(\"plot a graph of first 5 employees and their savings\")\n",
        "    response = ask_agent(agent=agent, query=query)\n",
        "\n",
        "    write_answer(json.loads(response))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIN90yzSxHwm",
        "outputId": "0ca2918f-a544-48bd-a629-a3ff92ea4817"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "0-Z_3FXZGDXL"
      },
      "outputs": [],
      "source": [
        "!streamlit run  app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt65LwzmGPJe",
        "outputId": "35e5d464-5cbb-405a-b6a5-ad0eef7ff5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 35.237.69.226\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGmQ6kPhGAZR",
        "outputId": "92a8e6cd-2022-4309-eefb-e06987816f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://odd-rules-peel.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGntx/ZMP769BvcdUg8WPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}